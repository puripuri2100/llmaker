//
// This file was generated by llmaker.
//

use super::lexer;
use super::types;
use std::iter::Peekable;

#[derive(Debug, Clone)]
pub enum ParseError {
  UnexpectedToken(lexer::Token),
  RedundantExpression(lexer::Token),
  Eof,
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
pub fn parse(tokens: Vec<lexer::Token>) -> Result<types::Term, ParseError> {
  let mut tokens = tokens.into_iter().peekable();
  let ret = _parse_fn_main(&mut tokens)?;
  match tokens.next() {
    Some(tok) => Err(ParseError::RedundantExpression(tok)),
    None => Ok(ret),
  }
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_fn_main<Tokens>(tokens: &mut Peekable<Tokens>) -> Result<types::Term, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  enum CodeType {
    Tok1,
    Other,
  }
  let code_type = tokens
    .peek()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok {
      (lexer::TokenKind::STR(_), _) => Ok(CodeType::Tok1),

      _ => Ok(CodeType::Other),
    });
  let main = match code_type? {
    CodeType::Tok1 => {
      let head = _parse_fn_head(tokens)?;
      let _gr = _parse_fn_gr(tokens)?;
      let setting = _parse_fn_setting(tokens)?;
      let body = _parse_fn_body(tokens)?;
      let _v = _parse_token_Tok_EOF(tokens)?;
      let mut v = head;
      v.reverse();
      (v, setting, body)
    }
    _ => return Err(ParseError::UnexpectedToken(tokens.next().unwrap())),
  };
  Ok(main)
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_fn_head<Tokens>(tokens: &mut Peekable<Tokens>) -> Result<types::Head, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  enum CodeType {
    Tok1,
    Other,
  }
  let code_type = tokens
    .peek()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok {
      (lexer::TokenKind::STR(_), _) => Ok(CodeType::Tok1),

      _ => Ok(CodeType::Other),
    });
  let main = match code_type? {
    CodeType::Tok1 => {
      let tok = _parse_token_Tok_STR(tokens)?;
      let tail = _parse_fn_head_tail(tokens)?;
      let mut tail_v = tail;
      let (stok, rng) = tok;
      let s = lexer::get_string(stok).unwrap();
      tail_v.push((rng, s));
      tail_v
    }
    _ => Vec::new(),
  };
  Ok(main)
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_fn_head_tail<Tokens>(tokens: &mut Peekable<Tokens>) -> Result<types::Head, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  enum CodeType {
    Tok1,
    Other,
  }
  let code_type = tokens
    .peek()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok {
      (lexer::TokenKind::STR(_), _) => Ok(CodeType::Tok1),

      _ => Ok(CodeType::Other),
    });
  let main = match code_type? {
    CodeType::Tok1 => {
      let head = _parse_token_Tok_STR(tokens)?;
      let tail = _parse_fn_head(tokens)?;
      let mut tail_v = tail;
      let (stok, rng) = head;
      let s = lexer::get_string(stok).unwrap();
      tail_v.push((rng, s));
      tail_v
    }
    _ => Vec::new(),
  };
  Ok(main)
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_fn_gr<Tokens>(tokens: &mut Peekable<Tokens>) -> Result<(), ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  enum CodeType {
    Tok1,
    Other,
  }
  let code_type = tokens
    .peek()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok {
      (lexer::TokenKind::GRAMMAR, _) => Ok(CodeType::Tok1),

      _ => Ok(CodeType::Other),
    });
  let main = match code_type? {
    CodeType::Tok1 => {
      let _v1 = _parse_token_Tok_GRAMMAR(tokens)?;
      let _v2 = _parse_token_Tok_SEMICOLON(tokens)?;
      ()
    }
    _ => return Err(ParseError::UnexpectedToken(tokens.next().unwrap())),
  };
  Ok(main)
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_fn_setting<Tokens>(tokens: &mut Peekable<Tokens>) -> Result<types::Setting, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  enum CodeType {
    Tok1,
    Other,
  }
  let code_type = tokens
    .peek()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok {
      (lexer::TokenKind::EXTERN, _) => Ok(CodeType::Tok1),

      _ => Ok(CodeType::Other),
    });
  let main = match code_type? {
    CodeType::Tok1 => {
      let _v1 = _parse_token_Tok_EXTERN(tokens)?;
      let _v2 = _parse_token_Tok_LCURLYBRACES(tokens)?;
      let types = _parse_fn_types(tokens)?;
      let _v3 = _parse_token_Tok_RCURLYBRACES(tokens)?;
      types
    }
    _ => return Err(ParseError::UnexpectedToken(tokens.next().unwrap())),
  };
  Ok(main)
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_fn_types<Tokens>(tokens: &mut Peekable<Tokens>) -> Result<types::Setting, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  enum CodeType {
    Tok1,
    Other,
  }
  let code_type = tokens
    .peek()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok {
      (lexer::TokenKind::ENUM, _) => Ok(CodeType::Tok1),

      _ => Ok(CodeType::Other),
    });
  let main = match code_type? {
    CodeType::Tok1 => {
      let _v1 = _parse_token_Tok_ENUM(tokens)?;
      let nametok = _parse_token_Tok_STR(tokens)?;
      let _v2 = _parse_token_Tok_LCURLYBRACES(tokens)?;
      let settokens_rev = _parse_fn_settokens(tokens)?;
      let _v3 = _parse_token_Tok_RCURLYBRACES(tokens)?;
      let (stok, _) = nametok;
      let s = lexer::get_string(stok).unwrap();
      let mut settokens = settokens_rev;
      settokens.reverse();
      (s, settokens)
    }
    _ => return Err(ParseError::UnexpectedToken(tokens.next().unwrap())),
  };
  Ok(main)
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_fn_settokens<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<Vec<(types::Range, String, types::TypeStr)>, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  enum CodeType {
    Tok1,
    Other,
  }
  let code_type = tokens
    .peek()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok {
      (lexer::TokenKind::CONSTRUCTOR(_), _) => Ok(CodeType::Tok1),

      _ => Ok(CodeType::Other),
    });
  let main = match code_type? {
    CodeType::Tok1 => {
      let settoken = _parse_fn_settoken(tokens)?;
      let settokens = _parse_fn_settokens_sub(tokens)?;
      let mut v = settokens;
      v.push(settoken);
      v
    }
    _ => Vec::new(),
  };
  Ok(main)
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_fn_settokens_sub<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<Vec<(types::Range, String, types::TypeStr)>, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  enum CodeType {
    Tok1,
    Other,
  }
  let code_type = tokens
    .peek()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok {
      (lexer::TokenKind::COMMA, _) => Ok(CodeType::Tok1),

      _ => Ok(CodeType::Other),
    });
  let main = match code_type? {
    CodeType::Tok1 => {
      let _v = _parse_token_Tok_COMMA(tokens)?;
      let tail = _parse_fn_settokens_sub_sub(tokens)?;
      tail
    }
    _ => Vec::new(),
  };
  Ok(main)
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_fn_settokens_sub_sub<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<Vec<(types::Range, String, types::TypeStr)>, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  enum CodeType {
    Tok1,
    Other,
  }
  let code_type = tokens
    .peek()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok {
      (lexer::TokenKind::CONSTRUCTOR(_), _) => Ok(CodeType::Tok1),

      _ => Ok(CodeType::Other),
    });
  let main = match code_type? {
    CodeType::Tok1 => {
      let settoken = _parse_fn_settoken(tokens)?;
      let settokens = _parse_fn_settokens_sub(tokens)?;
      let mut v = settokens;
      v.push(settoken);
      v
    }
    _ => Vec::new(),
  };
  Ok(main)
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_fn_settoken<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<(types::Range, String, types::TypeStr), ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  enum CodeType {
    Tok1,
    Other,
  }
  let code_type = tokens
    .peek()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok {
      (lexer::TokenKind::CONSTRUCTOR(_), _) => Ok(CodeType::Tok1),

      _ => Ok(CodeType::Other),
    });
  let main = match code_type? {
    CodeType::Tok1 => {
      let name = _parse_token_Tok_CONSTRUCTOR(tokens)?;
      let _v = _parse_token_Tok_ARROW(tokens)?;
      let typestr = _parse_token_Tok_STR(tokens)?;
      let (v1tok, rng1) = name;
      let v1 = lexer::get_string(v1tok).unwrap();
      let (v2tok, rng2) = typestr;
      let v2 = lexer::get_string(v2tok).unwrap();
      (types::Range::unite(rng1, rng2), v1, v2)
    }
    _ => return Err(ParseError::UnexpectedToken(tokens.next().unwrap())),
  };
  Ok(main)
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_fn_body<Tokens>(tokens: &mut Peekable<Tokens>) -> Result<Vec<types::Bnf>, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  enum CodeType {
    Tok1,
    Other,
  }
  let code_type = tokens
    .peek()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok {
      (lexer::TokenKind::PUB, _) | (lexer::TokenKind::VAR(_), _) => Ok(CodeType::Tok1),

      _ => Ok(CodeType::Other),
    });
  let main = match code_type? {
    CodeType::Tok1 => {
      let bnflst = _parse_fn_bnflst(tokens)?;
      let mut v = bnflst;
      v.reverse();
      v
    }
    _ => return Err(ParseError::UnexpectedToken(tokens.next().unwrap())),
  };
  Ok(main)
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_fn_bnflst<Tokens>(tokens: &mut Peekable<Tokens>) -> Result<Vec<types::Bnf>, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  enum CodeType {
    Tok1,
    Other,
  }
  let code_type = tokens
    .peek()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok {
      (lexer::TokenKind::PUB, _) | (lexer::TokenKind::VAR(_), _) => Ok(CodeType::Tok1),

      _ => Ok(CodeType::Other),
    });
  let main = match code_type? {
    CodeType::Tok1 => {
      let bnf = _parse_fn_bnf(tokens)?;
      let bnflst = _parse_fn_bnflst_sub(tokens)?;
      let mut v = bnflst;
      v.push(bnf);
      v
    }
    _ => Vec::new(),
  };
  Ok(main)
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_fn_bnflst_sub<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<Vec<types::Bnf>, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  enum CodeType {
    Tok1,
    Other,
  }
  let code_type = tokens
    .peek()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok {
      (lexer::TokenKind::SEMICOLON, _) => Ok(CodeType::Tok1),

      _ => Ok(CodeType::Other),
    });
  let main = match code_type? {
    CodeType::Tok1 => {
      let _v = _parse_token_Tok_SEMICOLON(tokens)?;
      let tail = _parse_fn_bnflst_sub_sub(tokens)?;
      tail
    }
    _ => Vec::new(),
  };
  Ok(main)
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_fn_bnflst_sub_sub<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<Vec<types::Bnf>, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  enum CodeType {
    Tok1,
    Other,
  }
  let code_type = tokens
    .peek()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok {
      (lexer::TokenKind::PUB, _) | (lexer::TokenKind::VAR(_), _) => Ok(CodeType::Tok1),

      _ => Ok(CodeType::Other),
    });
  let main = match code_type? {
    CodeType::Tok1 => {
      let bnf = _parse_fn_bnf(tokens)?;
      let bnflst = _parse_fn_bnflst_sub(tokens)?;
      let mut v = bnflst;
      v.push(bnf);
      v
    }
    _ => Vec::new(),
  };
  Ok(main)
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_fn_bnf<Tokens>(tokens: &mut Peekable<Tokens>) -> Result<types::Bnf, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  enum CodeType {
    Tok1,
    Tok2,
    Other,
  }
  let code_type = tokens
    .peek()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok {
      (lexer::TokenKind::PUB, _) => Ok(CodeType::Tok1),
      (lexer::TokenKind::VAR(_), _) => Ok(CodeType::Tok2),

      _ => Ok(CodeType::Other),
    });
  let main = match code_type? {
    CodeType::Tok1 => {
      let _v1 = _parse_token_Tok_PUB(tokens)?;
      let fnname = _parse_token_Tok_VAR(tokens)?;
      let _v2 = _parse_token_Tok_COLON(tokens)?;
      let typestr = _parse_token_Tok_STR(tokens)?;
      let _v3 = _parse_token_Tok_EQ(tokens)?;
      let _v4 = _parse_token_Tok_LCURLYBRACES(tokens)?;
      let bnf_code_lst = _parse_fn_bnf_code_lst(tokens)?;
      let v5 = _parse_token_Tok_RCURLYBRACES(tokens)?;
      let (nametok, rng1) = fnname;
      let name = lexer::get_string(nametok).unwrap();
      let (stok, _) = typestr;
      let s = lexer::get_string(stok).unwrap();
      let (_, rng2) = v5;
      let rng = types::Range::unite(rng1, rng2);
      types::Bnf::Pub(rng, name, s, bnf_code_lst)
    }
    CodeType::Tok2 => {
      let fnname = _parse_token_Tok_VAR(tokens)?;
      let _v2 = _parse_token_Tok_COLON(tokens)?;
      let typestr = _parse_token_Tok_STR(tokens)?;
      let _v3 = _parse_token_Tok_EQ(tokens)?;
      let _v4 = _parse_token_Tok_LCURLYBRACES(tokens)?;
      let bnf_code_lst_rev = _parse_fn_bnf_code_lst(tokens)?;
      let v5 = _parse_token_Tok_RCURLYBRACES(tokens)?;
      let (nametok, rng1) = fnname;
      let name = lexer::get_string(nametok).unwrap();
      let (stok, _) = typestr;
      let s = lexer::get_string(stok).unwrap();
      let (_, rng2) = v5;
      let rng = types::Range::unite(rng1, rng2);
      let mut bnf_code_lst = bnf_code_lst_rev;
      bnf_code_lst.reverse();
      types::Bnf::NonPub(rng, name, s, bnf_code_lst)
    }
    _ => return Err(ParseError::UnexpectedToken(tokens.next().unwrap())),
  };
  Ok(main)
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_fn_bnf_code_lst<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<Vec<types::Code>, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  enum CodeType {
    Tok1,
    Other,
  }
  let code_type = tokens
    .peek()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok {
      (lexer::TokenKind::ARROW, _) | (lexer::TokenKind::LBRACES, _) => Ok(CodeType::Tok1),

      _ => Ok(CodeType::Other),
    });
  let main = match code_type? {
    CodeType::Tok1 => {
      let bnf_code = _parse_fn_bnf_code(tokens)?;
      let bnf_code_lst = _parse_fn_bnf_code_lst_sub(tokens)?;
      let mut v = bnf_code_lst;
      v.push(bnf_code);
      v
    }
    _ => Vec::new(),
  };
  Ok(main)
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_fn_bnf_code_lst_sub<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<Vec<types::Code>, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  enum CodeType {
    Tok1,
    Other,
  }
  let code_type = tokens
    .peek()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok {
      (lexer::TokenKind::COMMA, _) => Ok(CodeType::Tok1),

      _ => Ok(CodeType::Other),
    });
  let main = match code_type? {
    CodeType::Tok1 => {
      let _v = _parse_token_Tok_COMMA(tokens)?;
      let tail = _parse_fn_bnf_code_lst_sub_sub(tokens)?;
      tail
    }
    _ => Vec::new(),
  };
  Ok(main)
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_fn_bnf_code_lst_sub_sub<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<Vec<types::Code>, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  enum CodeType {
    Tok1,
    Other,
  }
  let code_type = tokens
    .peek()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok {
      (lexer::TokenKind::ARROW, _) | (lexer::TokenKind::LBRACES, _) => Ok(CodeType::Tok1),

      _ => Ok(CodeType::Other),
    });
  let main = match code_type? {
    CodeType::Tok1 => {
      let bnf_code = _parse_fn_bnf_code(tokens)?;
      let bnf_code_lst = _parse_fn_bnf_code_lst_sub(tokens)?;
      let mut v = bnf_code_lst;
      v.push(bnf_code);
      v
    }
    _ => Vec::new(),
  };
  Ok(main)
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_fn_bnf_code<Tokens>(tokens: &mut Peekable<Tokens>) -> Result<types::Code, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  enum CodeType {
    Tok1,
    Tok2,
    Other,
  }
  let code_type = tokens
    .peek()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok {
      (lexer::TokenKind::LBRACES, _) => Ok(CodeType::Tok1),
      (lexer::TokenKind::ARROW, _) => Ok(CodeType::Tok2),

      _ => Ok(CodeType::Other),
    });
  let main = match code_type? {
    CodeType::Tok1 => {
      let fn_or_token = _parse_fn_fn_or_token(tokens)?;
      let fn_or_tokens = _parse_fn_fn_or_token_lst(tokens)?;
      let _v1 = _parse_token_Tok_ARROW(tokens)?;
      let _v2 = _parse_token_Tok_LCURLYBRACES(tokens)?;
      let code = _parse_token_Tok_STR(tokens)?;
      let _v3 = _parse_token_Tok_RCURLYBRACES(tokens)?;
      let (codetok, _) = code;
      let codestr = lexer::get_string(codetok).unwrap();
      let mut v = fn_or_tokens;
      v.push(fn_or_token);
      v.reverse();
      (v, codestr)
    }
    CodeType::Tok2 => {
      let _v1 = _parse_token_Tok_ARROW(tokens)?;
      let _v2 = _parse_token_Tok_LCURLYBRACES(tokens)?;
      let code = _parse_token_Tok_STR(tokens)?;
      let _v3 = _parse_token_Tok_RCURLYBRACES(tokens)?;
      let (codetok, _) = code;
      let codestr = lexer::get_string(codetok).unwrap();
      let mut v = Vec::new();
      v.reverse();
      (v, codestr)
    }
    _ => return Err(ParseError::UnexpectedToken(tokens.next().unwrap())),
  };
  Ok(main)
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_fn_fn_or_token_lst<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<Vec<(String, types::FnOrToken)>, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  enum CodeType {
    Tok1,
    Other,
  }
  let code_type = tokens
    .peek()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok {
      (lexer::TokenKind::LBRACES, _) => Ok(CodeType::Tok1),

      _ => Ok(CodeType::Other),
    });
  let main = match code_type? {
    CodeType::Tok1 => {
      let f = _parse_fn_fn_or_token(tokens)?;
      let fs = _parse_fn_fn_or_token_lst_sub(tokens)?;
      let mut v = fs;
      v.push(f);
      v
    }
    _ => Vec::new(),
  };
  Ok(main)
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_fn_fn_or_token_lst_sub<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<Vec<(String, types::FnOrToken)>, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  enum CodeType {
    Tok1,
    Other,
  }
  let code_type = tokens
    .peek()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok {
      (lexer::TokenKind::LBRACES, _) => Ok(CodeType::Tok1),

      _ => Ok(CodeType::Other),
    });
  let main = match code_type? {
    CodeType::Tok1 => {
      let f = _parse_fn_fn_or_token(tokens)?;
      let fs = _parse_fn_fn_or_token_lst(tokens)?;
      let mut v = fs;
      v.push(f);
      v
    }
    _ => Vec::new(),
  };
  Ok(main)
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_fn_fn_or_token<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<(String, types::FnOrToken), ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  enum CodeType {
    Tok1,
    Other,
  }
  let code_type = tokens
    .peek()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok {
      (lexer::TokenKind::LBRACES, _) => Ok(CodeType::Tok1),

      _ => Ok(CodeType::Other),
    });
  let main = match code_type? {
    CodeType::Tok1 => {
      let _v1 = _parse_token_Tok_LBRACES(tokens)?;
      let name = _parse_token_Tok_VAR(tokens)?;
      let _v2 = _parse_token_Tok_COLON(tokens)?;
      let tail = _parse_fn_fn_or_token_sub(tokens)?;
      let (nametok, _) = name;
      let namestr = lexer::get_string(nametok).unwrap();
      (namestr, tail)
    }
    _ => return Err(ParseError::UnexpectedToken(tokens.next().unwrap())),
  };
  Ok(main)
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_fn_fn_or_token_sub<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<types::FnOrToken, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  enum CodeType {
    Tok1,
    Tok2,
    Other,
  }
  let code_type = tokens
    .peek()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok {
      (lexer::TokenKind::VAR(_), _) => Ok(CodeType::Tok1),
      (lexer::TokenKind::CONSTRUCTOR(_), _) => Ok(CodeType::Tok2),

      _ => Ok(CodeType::Other),
    });
  let main = match code_type? {
    CodeType::Tok1 => {
      let fnname = _parse_token_Tok_VAR(tokens)?;
      let _v3 = _parse_token_Tok_RBRACES(tokens)?;
      let (fnnametok, _) = fnname;
      let fnnamestr = lexer::get_string(fnnametok).unwrap();
      types::FnOrToken::Function(fnnamestr)
    }
    CodeType::Tok2 => {
      let tokname = _parse_token_Tok_CONSTRUCTOR(tokens)?;
      let _v3 = _parse_token_Tok_RBRACES(tokens)?;
      let (toknametok, _) = tokname;
      let toknamestr = lexer::get_string(toknametok).unwrap();
      types::FnOrToken::Token(toknamestr)
    }
    _ => return Err(ParseError::UnexpectedToken(tokens.next().unwrap())),
  };
  Ok(main)
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_token_Tok_EOF<Tokens>(tokens: &mut Peekable<Tokens>) -> Result<lexer::Token, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  tokens
    .next()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok.clone() {
      (lexer::TokenKind::EOF, _) => Ok(tok),
      _ => Err(ParseError::UnexpectedToken(tok)),
    })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_token_Tok_GRAMMAR<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<lexer::Token, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  tokens
    .next()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok.clone() {
      (lexer::TokenKind::GRAMMAR, _) => Ok(tok),
      _ => Err(ParseError::UnexpectedToken(tok)),
    })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_token_Tok_EXTERN<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<lexer::Token, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  tokens
    .next()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok.clone() {
      (lexer::TokenKind::EXTERN, _) => Ok(tok),
      _ => Err(ParseError::UnexpectedToken(tok)),
    })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_token_Tok_ENUM<Tokens>(tokens: &mut Peekable<Tokens>) -> Result<lexer::Token, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  tokens
    .next()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok.clone() {
      (lexer::TokenKind::ENUM, _) => Ok(tok),
      _ => Err(ParseError::UnexpectedToken(tok)),
    })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_token_Tok_PUB<Tokens>(tokens: &mut Peekable<Tokens>) -> Result<lexer::Token, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  tokens
    .next()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok.clone() {
      (lexer::TokenKind::PUB, _) => Ok(tok),
      _ => Err(ParseError::UnexpectedToken(tok)),
    })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_token_Tok_VAR<Tokens>(tokens: &mut Peekable<Tokens>) -> Result<lexer::Token, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  tokens
    .next()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok.clone() {
      (lexer::TokenKind::VAR(_), _) => Ok(tok),
      _ => Err(ParseError::UnexpectedToken(tok)),
    })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_token_Tok_CONSTRUCTOR<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<lexer::Token, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  tokens
    .next()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok.clone() {
      (lexer::TokenKind::CONSTRUCTOR(_), _) => Ok(tok),
      _ => Err(ParseError::UnexpectedToken(tok)),
    })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_token_Tok_LCURLYBRACES<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<lexer::Token, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  tokens
    .next()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok.clone() {
      (lexer::TokenKind::LCURLYBRACES, _) => Ok(tok),
      _ => Err(ParseError::UnexpectedToken(tok)),
    })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_token_Tok_RCURLYBRACES<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<lexer::Token, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  tokens
    .next()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok.clone() {
      (lexer::TokenKind::RCURLYBRACES, _) => Ok(tok),
      _ => Err(ParseError::UnexpectedToken(tok)),
    })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_token_Tok_EQ<Tokens>(tokens: &mut Peekable<Tokens>) -> Result<lexer::Token, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  tokens
    .next()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok.clone() {
      (lexer::TokenKind::EQ, _) => Ok(tok),
      _ => Err(ParseError::UnexpectedToken(tok)),
    })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_token_Tok_COMMA<Tokens>(tokens: &mut Peekable<Tokens>) -> Result<lexer::Token, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  tokens
    .next()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok.clone() {
      (lexer::TokenKind::COMMA, _) => Ok(tok),
      _ => Err(ParseError::UnexpectedToken(tok)),
    })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_token_Tok_SEMICOLON<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<lexer::Token, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  tokens
    .next()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok.clone() {
      (lexer::TokenKind::SEMICOLON, _) => Ok(tok),
      _ => Err(ParseError::UnexpectedToken(tok)),
    })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_token_Tok_COLON<Tokens>(tokens: &mut Peekable<Tokens>) -> Result<lexer::Token, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  tokens
    .next()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok.clone() {
      (lexer::TokenKind::COLON, _) => Ok(tok),
      _ => Err(ParseError::UnexpectedToken(tok)),
    })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_token_Tok_LBRACES<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<lexer::Token, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  tokens
    .next()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok.clone() {
      (lexer::TokenKind::LBRACES, _) => Ok(tok),
      _ => Err(ParseError::UnexpectedToken(tok)),
    })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_token_Tok_RBRACES<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<lexer::Token, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  tokens
    .next()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok.clone() {
      (lexer::TokenKind::RBRACES, _) => Ok(tok),
      _ => Err(ParseError::UnexpectedToken(tok)),
    })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_token_Tok_ARROW<Tokens>(tokens: &mut Peekable<Tokens>) -> Result<lexer::Token, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  tokens
    .next()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok.clone() {
      (lexer::TokenKind::ARROW, _) => Ok(tok),
      _ => Err(ParseError::UnexpectedToken(tok)),
    })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_token_Tok_STR<Tokens>(tokens: &mut Peekable<Tokens>) -> Result<lexer::Token, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  tokens
    .next()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok.clone() {
      (lexer::TokenKind::STR(_), _) => Ok(tok),
      _ => Err(ParseError::UnexpectedToken(tok)),
    })
}
